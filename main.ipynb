{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90410a7-b5be-4753-9f26-28b7a40935fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "from dataset_management.dataloader import Seq2PointDataLoader\n",
    "import builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e2a85c-e20e-4349-a339-badf38ad8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.DATASET_CONFIG = get_config_from_json(description=\"Dataset Management\", config_file=\"configs/dataset_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TRAINING_CONFIG['EXPERIMENT_PATH'] = f'experiments/{TRAINING_CONFIG[\"TARGET_APPLIANCE\"]}/{TRAINING_CONFIG[\"TARGET_HOUSES\"][\"TRAIN\"]}/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ba9340-62ed-4205-8d4c-3a79f2177363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the refit_loader configuration \n",
      "{'DATA_FOLDER': 'data/refit/', 'DATA_TYPE': '.csv', 'README_FILE': 'refit_loader/REFIT_Readme.txt', 'REFIT_HOUSES': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]}\n",
      "\n",
      "Loading specified buildings: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "Parsing the readme file specified: refit_loader/REFIT_Readme.txt\n",
      "Loading data for appliance MICROWAVE ...\n",
      "Fetching MICROWAVE data for House 2\n",
      "Fetching MICROWAVE data for House 3\n",
      "Fetching MICROWAVE data for House 4\n",
      "Resampling for house number:  2\n",
      "Resampling for house number:  3\n",
      "Resampling for house number:  4\n",
      "Updating data with resampled dataset...\n",
      "Subetting dataset with 10 days of most activities for House 2\n",
      "Estimating active durations of: microwave\n",
      "Subetting dataset with 10 days of most activities for House 3\n",
      "Estimating active durations of: microwave\n",
      "Subetting dataset with 10 days of most activities for House 4\n",
      "Estimating active durations of: microwave\n",
      "Updating data with selected active appliance activities...\n",
      "Updating splits with specified proportion from every target house...\n",
      "Normalization is being performed for training a model. Scalers will be computed/fit considering the train_split and using those scalers, all splits will be normalized/transformed.\n",
      "Updating splits with normalized data splits...\n",
      "\n",
      "Creating dataloaders...\n",
      "Data Loaders are successfully initialized.\n"
     ]
    }
   ],
   "source": [
    "dataloaders = Seq2PointDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = SEQ2POINT().to(set_GPU())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 6,\n",
      " 'EXPERIMENT_PATH': 'experiments/MICROWAVE/[2, 3, 4]/',\n",
      " 'LEARNING_RATE': 0.0001,\n",
      " 'LOSS': 'nn.MSELoss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NORMALIZE': 'Standard',\n",
      " 'NUM_EPOCHS': 12,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SPLIT_PROPORTION': {'TEST_PERCENT': 0.2,\n",
      "                      'TRAIN_PERCENT': 0.6,\n",
      "                      'VALIDATE_PERCENT': 0.2},\n",
      " 'SUBSET_DAYS': 10,\n",
      " 'TARGET_APPLIANCE': 'MICROWAVE',\n",
      " 'TARGET_HOUSES': {'TEST': [2, 3, 4],\n",
      "                   'TRAIN': [2, 3, 4],\n",
      "                   'VALIDATE': [2, 3, 4]},\n",
      " 'TEST_BATCH_SIZE': 1000,\n",
      " 'THRESHOLD': 100.0,\n",
      " 'TRAIN_BATCH_SIZE': 1000,\n",
      " 'VALIDATION_BATCH_SIZE': 1000}\n",
      "\n",
      "Summary of the model architecture\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 50, 599]             12,550\n",
      "|    └─ReLU: 2-15                        [-1, 50, 599]             --\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─Linear: 2-16                      [-1, 1024]                30,669,824\n",
      "|    └─ReLU: 2-17                        [-1, 1024]                --\n",
      "|    └─Linear: 2-18                      [-1, 1]                   1,025\n",
      "==========================================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 83.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 117.14\n",
      "Estimated Total Size (MB): 118.07\n",
      "==========================================================================================\n",
      "Loss is set with loss_reduction = mean\n",
      "\n",
      "\n",
      "Training the model architecture...\n",
      "Epoch : [1/12] | Step : [50/195]|  Average Training Loss : 0.6870009702444076\n",
      "Epoch : [1/12] | Step : [100/195]|  Average Training Loss : 0.8362050253004418\n",
      "Epoch : [1/12] | Step : [150/195]|  Average Training Loss : 0.9662164804395676\n",
      "Epoch : [1/12] | Step : [20/65]|  Average Validation Loss : 0.6092493875185028\n",
      "Epoch : [1/12] | Step : [40/65]|  Average Validation Loss : 0.6986231640446932\n",
      "Epoch : [1/12] | Step : [60/65]|  Average Validation Loss : 2.423862209155535\n",
      "==================================================================================================================================================\n",
      "Epoch : [1/12] | Training Loss : 1.003732285390232, | Validation Loss : 2.4680859881668136, | Time consumption: 0:00:54.342731s\n",
      "==================================================================================================================================================\n",
      "Epoch : [2/12] | Step : [50/195]|  Average Training Loss : 0.6555758116318612\n",
      "Epoch : [2/12] | Step : [100/195]|  Average Training Loss : 0.8158140062639359\n",
      "Epoch : [2/12] | Step : [150/195]|  Average Training Loss : 0.9513903358302923\n",
      "Epoch : [2/12] | Step : [20/65]|  Average Validation Loss : 0.630362289363984\n",
      "Epoch : [2/12] | Step : [40/65]|  Average Validation Loss : 0.7135154425923247\n",
      "Epoch : [2/12] | Step : [60/65]|  Average Validation Loss : 2.485016784766534\n",
      "==================================================================================================================================================\n",
      "Epoch : [2/12] | Training Loss : 0.9901567971279944, | Validation Loss : 2.5245487173266996, | Time consumption: 0:00:54.148773s\n",
      "==================================================================================================================================================\n",
      "Epoch : [3/12] | Step : [50/195]|  Average Training Loss : 0.6537412329844665\n",
      "Epoch : [3/12] | Step : [100/195]|  Average Training Loss : 0.8094885034248\n",
      "Epoch : [3/12] | Step : [150/195]|  Average Training Loss : 0.943407017516826\n",
      "Epoch : [3/12] | Step : [20/65]|  Average Validation Loss : 0.5958667134982534\n",
      "Epoch : [3/12] | Step : [40/65]|  Average Validation Loss : 0.6946156816951315\n",
      "Epoch : [3/12] | Step : [60/65]|  Average Validation Loss : 2.4302828470119797\n",
      "==================================================================================================================================================\n",
      "Epoch : [3/12] | Training Loss : 0.9792676587950271, | Validation Loss : 2.465542747031829, | Time consumption: 0:00:55.289015s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-12-05_best_loss_2 model...\n",
      "\n",
      "Epoch : [4/12] | Step : [50/195]|  Average Training Loss : 0.6508492875593948\n",
      "Epoch : [4/12] | Step : [100/195]|  Average Training Loss : 0.8041669965258916\n",
      "Epoch : [4/12] | Step : [150/195]|  Average Training Loss : 0.9316588597906714\n",
      "Epoch : [4/12] | Step : [20/65]|  Average Validation Loss : 0.5930004389956594\n",
      "Epoch : [4/12] | Step : [40/65]|  Average Validation Loss : 0.691346488322597\n",
      "Epoch : [4/12] | Step : [60/65]|  Average Validation Loss : 2.4104721731661507\n",
      "==================================================================================================================================================\n",
      "Epoch : [4/12] | Training Loss : 0.9716423423715288, | Validation Loss : 2.4456479494173364, | Time consumption: 0:00:58.322328s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-12-05_best_loss_2 model...\n",
      "\n",
      "Epoch : [5/12] | Step : [50/195]|  Average Training Loss : 0.6410877903585788\n",
      "Epoch : [5/12] | Step : [100/195]|  Average Training Loss : 0.7981693925173022\n",
      "Epoch : [5/12] | Step : [150/195]|  Average Training Loss : 0.9240905800457888\n",
      "Epoch : [5/12] | Step : [20/65]|  Average Validation Loss : 0.5779110216630216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidation_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massess_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Repos\\1.11\\seq2point\\seq2point\\seq2point.py:151\u001B[0m, in \u001B[0;36mSEQ2POINT.run\u001B[1;34m(self, train_loader, validation_loader, assess_training)\u001B[0m\n\u001B[0;32m    148\u001B[0m     criterion \u001B[38;5;241m=\u001B[39m set_criterion()\n\u001B[0;32m    149\u001B[0m     optimizer \u001B[38;5;241m=\u001B[39m set_optimization(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 151\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork_train\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massess_training\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m TRAINING_CONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPRE_TRAINED_MODEL_FLAG\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Repos\\1.11\\seq2point\\training\\train.py:86\u001B[0m, in \u001B[0;36mnetwork_train\u001B[1;34m(model, criterion, optimizer, train_loader, validation_loader, assess_training)\u001B[0m\n\u001B[0;32m     84\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 86\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (timestep, x_value, y_value) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(validation_loader):\n\u001B[0;32m     87\u001B[0m         x_value \u001B[38;5;241m=\u001B[39m x_value[:, \u001B[38;5;28;01mNone\u001B[39;00m]\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mFloatTensor)\u001B[38;5;241m.\u001B[39mto(set_GPU())\n\u001B[0;32m     88\u001B[0m         y_value \u001B[38;5;241m=\u001B[39m y_value[:, \u001B[38;5;28;01mNone\u001B[39;00m]\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mFloatTensor)\u001B[38;5;241m.\u001B[39mto(set_GPU())\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    723\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    172\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [default_collate(samples) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    172\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m--> 175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mdefault_collate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001B[0m, in \u001B[0;36mdefault_collate\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np_str_obj_array_pattern\u001B[38;5;241m.\u001B[39msearch(elem\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mstr) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    147\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[1;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_collate([torch\u001B[38;5;241m.\u001B[39mas_tensor(b) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m batch])\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m elem\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m ():  \u001B[38;5;66;03m# scalars\u001B[39;00m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mas_tensor(batch)\n",
      "File \u001B[1;32m~\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:149\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np_str_obj_array_pattern\u001B[38;5;241m.\u001B[39msearch(elem\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mstr) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    147\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[1;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_collate([\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m batch])\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m elem\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m ():  \u001B[38;5;66;03m# scalars\u001B[39;00m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mas_tensor(batch)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results = network.run(dataloaders.train_dataloader, dataloaders.validation_dataloader, assess_training=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plot_traces(traces\u001B[38;5;241m=\u001B[39m[\u001B[43mresults\u001B[49m[\u001B[38;5;241m0\u001B[39m], results[\u001B[38;5;241m1\u001B[39m]], labels \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining loss\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation loss\u001B[39m\u001B[38;5;124m'\u001B[39m], axis_labels\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss Score\u001B[39m\u001B[38;5;124m'\u001B[39m] , title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining Loss vs Validation Loss\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "plot_traces(traces=[results[0], results[1]], labels = ['training loss', 'validation loss'], axis_labels=['Epoch', 'Loss Score'] , title=\"Training Loss vs Validation Loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_traces(traces=[results[2], results[3]], labels = ['Recall', 'Precision'], axis_labels=['Epoch', 'Score'] , title=\"Recall vs Precision per Epoch\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d8f1d2-f0a1-40d6-b9ba-6a9bee0c63d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_network = SEQ2POINT().to(set_GPU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30dee667-912b-4c0f-84ba-dfebfc0a06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...experiments/MICROWAVE/[2, 3, 4]/models\\2022-12-05_best_loss_2.pt\n",
      "Model's state_dict:\n",
      "conv.1.weight \t torch.Size([30, 1, 10])\n",
      "conv.1.bias \t torch.Size([30])\n",
      "conv.4.weight \t torch.Size([30, 30, 8])\n",
      "conv.4.bias \t torch.Size([30])\n",
      "conv.7.weight \t torch.Size([40, 30, 6])\n",
      "conv.7.bias \t torch.Size([40])\n",
      "conv.10.weight \t torch.Size([50, 40, 5])\n",
      "conv.10.bias \t torch.Size([50])\n",
      "conv.13.weight \t torch.Size([50, 50, 5])\n",
      "conv.13.bias \t torch.Size([50])\n",
      "dense.0.weight \t torch.Size([1024, 29950])\n",
      "dense.0.bias \t torch.Size([1024])\n",
      "dense.2.weight \t torch.Size([1, 1024])\n",
      "dense.2.bias \t torch.Size([1])\n",
      "Loss is set with loss_reduction = mean\n",
      "Average Test Loss : 1.1194093727864898, Average Recall : 0.0, Average Precision : 0.0, Time consumption: 0:00:14.673267s\n"
     ]
    }
   ],
   "source": [
    "test_network.inference(dataloaders.test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (3.19.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (2.11.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (1.48.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (65.3.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (1.23.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mahno\\anaconda\\envs\\torchy\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard\n",
    "! tensorboard --logdir=runs --port=6006"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
