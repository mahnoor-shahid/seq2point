{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "from refit_loader.data_loader import REFIT_Loader\n",
    "from dataset_management.dataloader import Seq2PointDataLoader\n",
    "import builtins\n",
    "import os\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.DATASET_CONFIG = get_config_from_json(description=\"Dataset Management\", config_file=\"configs/dataset_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb770e1a-7356-4d37-8a94-f5ad7c6b5b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the refit_loader configuration \n",
      "{'DATA_FOLDER': 'data/refit/', 'DATA_TYPE': '.csv', 'README_FILE': 'refit_loader/REFIT_Readme.txt', 'REFIT_HOUSES': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]}\n",
      "\n",
      "Loading specified buildings: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "Parsing the readme file specified: refit_loader/REFIT_Readme.txt\n",
      "Loading data for appliance KETTLE ...\n",
      "Fetching KETTLE data for House 2\n",
      "Resampling for house number:  2\n",
      "Creating 12 smaller subsets from complete dataset of House 2\n",
      "Estimating active durations of: kettle\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n",
      "\n",
      "\n",
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 5,\n",
      " 'LEARNING_RATE': 0.001,\n",
      " 'LOAD_MODEL': 'models/best_model/2022-11-17_best_loss_9.pt',\n",
      " 'LOSS': 'nn.L1Loss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NUM_EPOCHS': 20,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SAVE_MODEL': 'models/',\n",
      " 'TEST_BATCH_SIZE': 512,\n",
      " 'TRAIN_BATCH_SIZE': 512,\n",
      " 'VALIDATION_BATCH_SIZE': 512}\n",
      "\n",
      "Summary of the model architecture\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 50, 599]             12,550\n",
      "|    └─ReLU: 2-15                        [-1, 50, 599]             --\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─Linear: 2-16                      [-1, 1024]                30,669,824\n",
      "|    └─ReLU: 2-17                        [-1, 1024]                --\n",
      "|    └─Linear: 2-18                      [-1, 1]                   1,025\n",
      "==========================================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 83.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 117.14\n",
      "Estimated Total Size (MB): 118.07\n",
      "==========================================================================================\n",
      "Loss is set with loss_reduction = mean\n",
      "\n",
      "\n",
      "Training the model architecture...\n",
      "Epoch : [1/20] | Step : [20/152]|  Average Training Loss : 155.27264580726623\n",
      "Epoch : [1/20] | Step : [40/152]|  Average Training Loss : 84.54706169515848\n",
      "Epoch : [1/20] | Step : [60/152]|  Average Training Loss : 59.92044864435835\n",
      "Epoch : [1/20] | Step : [80/152]|  Average Training Loss : 49.44866542063537\n",
      "Epoch : [1/20] | Step : [100/152]|  Average Training Loss : 42.346540110018395\n",
      "Epoch : [1/20] | Step : [120/152]|  Average Training Loss : 35.28986909429489\n",
      "Epoch : [1/20] | Step : [140/152]|  Average Training Loss : 31.802155737221515\n",
      "Epoch : [1/20] | Step : [20/51]|  Average Validation Loss : 5.633413902897155\n",
      "Epoch : [1/20] | Step : [40/51]|  Average Validation Loss : 4.830744970351224\n",
      "==================================================================================================================================================\n",
      "Epoch : [1/20] | Training Loss : 29.29174695024056, | Validation Loss : 8.51262249411586, | Time consumption: 0:01:01.026287s\n",
      "==================================================================================================================================================\n",
      "Epoch : [2/20] | Step : [20/152]|  Average Training Loss : 18.245782747393243\n",
      "Epoch : [2/20] | Step : [40/152]|  Average Training Loss : 15.495465566723578\n",
      "Epoch : [2/20] | Step : [60/152]|  Average Training Loss : 13.814077921056015\n",
      "Epoch : [2/20] | Step : [80/152]|  Average Training Loss : 14.853718176693292\n",
      "Epoch : [2/20] | Step : [100/152]|  Average Training Loss : 14.667363226911112\n",
      "Epoch : [2/20] | Step : [120/152]|  Average Training Loss : 12.222875564894517\n",
      "Epoch : [2/20] | Step : [140/152]|  Average Training Loss : 12.026099027609183\n",
      "Epoch : [2/20] | Step : [20/51]|  Average Validation Loss : 5.6216038117287095\n",
      "Epoch : [2/20] | Step : [40/51]|  Average Validation Loss : 4.8061261726630615\n",
      "==================================================================================================================================================\n",
      "Epoch : [2/20] | Training Loss : 11.076688124227363, | Validation Loss : 8.490898084872706, | Time consumption: 0:01:00.807636s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-11-17_best_loss_8 model...\n",
      "\n",
      "Epoch : [3/20] | Step : [20/152]|  Average Training Loss : 18.232758974400348\n",
      "Epoch : [3/20] | Step : [40/152]|  Average Training Loss : 15.48401089448962\n",
      "Epoch : [3/20] | Step : [60/152]|  Average Training Loss : 13.804570631531533\n",
      "Epoch : [3/20] | Step : [80/152]|  Average Training Loss : 14.845112407987653\n",
      "Epoch : [3/20] | Step : [100/152]|  Average Training Loss : 14.660163335681137\n",
      "Epoch : [3/20] | Step : [120/152]|  Average Training Loss : 12.21683747030561\n",
      "Epoch : [3/20] | Step : [140/152]|  Average Training Loss : 12.020388466660592\n",
      "Epoch : [3/20] | Step : [20/51]|  Average Validation Loss : 5.617301666383719\n",
      "Epoch : [3/20] | Step : [40/51]|  Average Validation Loss : 4.79480238447286\n",
      "==================================================================================================================================================\n",
      "Epoch : [3/20] | Training Loss : 11.071423330119147, | Validation Loss : 8.481070818289641, | Time consumption: 0:01:01.324497s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-11-17_best_loss_8 model...\n",
      "\n",
      "Epoch : [4/20] | Step : [20/152]|  Average Training Loss : 18.230045146370685\n",
      "Epoch : [4/20] | Step : [40/152]|  Average Training Loss : 15.482013754807667\n",
      "Epoch : [4/20] | Step : [60/152]|  Average Training Loss : 13.803071994490528\n",
      "Epoch : [4/20] | Step : [80/152]|  Average Training Loss : 14.843026306590492\n",
      "Epoch : [4/20] | Step : [100/152]|  Average Training Loss : 14.65848525565576\n",
      "Epoch : [4/20] | Step : [120/152]|  Average Training Loss : 12.21545202445653\n",
      "Epoch : [4/20] | Step : [140/152]|  Average Training Loss : 12.018598234972952\n",
      "Epoch : [4/20] | Step : [20/51]|  Average Validation Loss : 5.617187746610432\n",
      "Epoch : [4/20] | Step : [40/51]|  Average Validation Loss : 4.792391641569196\n",
      "==================================================================================================================================================\n",
      "Epoch : [4/20] | Training Loss : 11.06977275588023, | Validation Loss : 8.478847176078235, | Time consumption: 0:01:01.409161s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-11-17_best_loss_8 model...\n",
      "\n",
      "Epoch : [5/20] | Step : [20/152]|  Average Training Loss : 18.22839918745758\n",
      "Epoch : [5/20] | Step : [40/152]|  Average Training Loss : 15.480963112333393\n",
      "Epoch : [5/20] | Step : [60/152]|  Average Training Loss : 13.802175548542225\n",
      "Epoch : [5/20] | Step : [80/152]|  Average Training Loss : 14.841838881028185\n",
      "Epoch : [5/20] | Step : [100/152]|  Average Training Loss : 14.657461552212062\n",
      "Epoch : [5/20] | Step : [120/152]|  Average Training Loss : 12.214574972937301\n",
      "Epoch : [5/20] | Step : [140/152]|  Average Training Loss : 12.0178716141166\n",
      "Epoch : [5/20] | Step : [20/51]|  Average Validation Loss : 5.616974129923619\n",
      "Epoch : [5/20] | Step : [40/51]|  Average Validation Loss : 4.79135878690995\n",
      "==================================================================================================================================================\n",
      "Epoch : [5/20] | Training Loss : 11.069104177744054, | Validation Loss : 8.47795417102544, | Time consumption: 0:01:01.588829s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-11-17_best_loss_8 model...\n",
      "\n",
      "Epoch : [6/20] | Step : [20/152]|  Average Training Loss : 18.22810207459661\n",
      "Epoch : [6/20] | Step : [40/152]|  Average Training Loss : 15.480797355587583\n",
      "Epoch : [6/20] | Step : [60/152]|  Average Training Loss : 13.80206482032445\n",
      "Epoch : [6/20] | Step : [80/152]|  Average Training Loss : 14.841824306590752\n",
      "Epoch : [6/20] | Step : [100/152]|  Average Training Loss : 14.657413530652484\n",
      "Epoch : [6/20] | Step : [120/152]|  Average Training Loss : 12.214539574107024\n",
      "Epoch : [6/20] | Step : [140/152]|  Average Training Loss : 12.017649200279694\n",
      "Epoch : [6/20] | Step : [20/51]|  Average Validation Loss : 5.616540972739676\n",
      "Epoch : [6/20] | Step : [40/51]|  Average Validation Loss : 4.791444454070915\n",
      "==================================================================================================================================================\n",
      "Epoch : [6/20] | Training Loss : 11.068897874657152, | Validation Loss : 8.478000701340767, | Time consumption: 0:01:01.835598s\n",
      "==================================================================================================================================================\n",
      "Epoch : [7/20] | Step : [20/152]|  Average Training Loss : 18.22800009523853\n",
      "Epoch : [7/20] | Step : [40/152]|  Average Training Loss : 15.480717694696887\n",
      "Epoch : [7/20] | Step : [60/152]|  Average Training Loss : 13.802038170338255\n",
      "Epoch : [7/20] | Step : [80/152]|  Average Training Loss : 14.84159161897353\n",
      "Epoch : [7/20] | Step : [100/152]|  Average Training Loss : 14.657230029458388\n",
      "Epoch : [7/20] | Step : [120/152]|  Average Training Loss : 12.2143781872339\n",
      "Epoch : [7/20] | Step : [140/152]|  Average Training Loss : 12.017482877601244\n",
      "Epoch : [7/20] | Step : [20/51]|  Average Validation Loss : 5.616626968377386\n",
      "Epoch : [7/20] | Step : [40/51]|  Average Validation Loss : 4.791042931430274\n",
      "==================================================================================================================================================\n",
      "Epoch : [7/20] | Training Loss : 11.068748302725576, | Validation Loss : 8.477713331280563, | Time consumption: 0:01:01.889359s\n",
      "==================================================================================================================================================\n",
      "Epoch : [8/20] | Step : [20/152]|  Average Training Loss : 18.227971028630783\n",
      "Epoch : [8/20] | Step : [40/152]|  Average Training Loss : 15.480647868140158\n",
      "Epoch : [8/20] | Step : [60/152]|  Average Training Loss : 13.801960799206942\n",
      "Epoch : [8/20] | Step : [80/152]|  Average Training Loss : 14.841469771209109\n",
      "Epoch : [8/20] | Step : [100/152]|  Average Training Loss : 14.657172560866911\n",
      "Epoch : [8/20] | Step : [120/152]|  Average Training Loss : 12.214346377562727\n",
      "Epoch : [8/20] | Step : [140/152]|  Average Training Loss : 12.017427981106298\n",
      "Epoch : [8/20] | Step : [20/51]|  Average Validation Loss : 5.616770325200923\n",
      "Epoch : [8/20] | Step : [40/51]|  Average Validation Loss : 4.790957187070307\n",
      "==================================================================================================================================================\n",
      "Epoch : [8/20] | Training Loss : 11.068709510045288, | Validation Loss : 8.477689206500322, | Time consumption: 0:01:02.230255s\n",
      "==================================================================================================================================================\n",
      "Epoch : [9/20] | Step : [20/152]|  Average Training Loss : 18.22793132463348\n",
      "Epoch : [9/20] | Step : [40/152]|  Average Training Loss : 15.48067627451187\n",
      "Epoch : [9/20] | Step : [60/152]|  Average Training Loss : 13.801961998103206\n",
      "Epoch : [9/20] | Step : [80/152]|  Average Training Loss : 14.84141383596899\n",
      "Epoch : [9/20] | Step : [100/152]|  Average Training Loss : 14.65707707400049\n",
      "Epoch : [9/20] | Step : [120/152]|  Average Training Loss : 12.214245740994125\n",
      "Epoch : [9/20] | Step : [140/152]|  Average Training Loss : 12.017340873476456\n",
      "Epoch : [9/20] | Step : [20/51]|  Average Validation Loss : 5.616404618517118\n",
      "Epoch : [9/20] | Step : [40/51]|  Average Validation Loss : 4.790598145329568\n",
      "==================================================================================================================================================\n",
      "Epoch : [9/20] | Training Loss : 11.068612718577901, | Validation Loss : 8.47732741191416, | Time consumption: 0:01:02.345964s\n",
      "==================================================================================================================================================\n",
      "Saving the 2022-11-17_best_loss_8 model...\n",
      "\n",
      "Epoch : [10/20] | Step : [20/152]|  Average Training Loss : 18.227846633708758\n",
      "Epoch : [10/20] | Step : [40/152]|  Average Training Loss : 15.480601514376394\n",
      "Epoch : [10/20] | Step : [60/152]|  Average Training Loss : 13.80191187361955\n",
      "Epoch : [10/20] | Step : [80/152]|  Average Training Loss : 14.841361220968679\n",
      "Epoch : [10/20] | Step : [100/152]|  Average Training Loss : 14.657017092347505\n",
      "Epoch : [10/20] | Step : [120/152]|  Average Training Loss : 12.214192072818074\n",
      "Epoch : [10/20] | Step : [140/152]|  Average Training Loss : 12.017285600920552\n",
      "Epoch : [10/20] | Step : [20/51]|  Average Validation Loss : 5.616311426363973\n",
      "Epoch : [10/20] | Step : [40/51]|  Average Validation Loss : 4.790721726810443\n",
      "==================================================================================================================================================\n",
      "Epoch : [10/20] | Training Loss : 11.068562429576165, | Validation Loss : 8.477407403351904, | Time consumption: 0:01:02.178368s\n",
      "==================================================================================================================================================\n",
      "Epoch : [11/20] | Step : [20/152]|  Average Training Loss : 18.227851632414534\n",
      "Epoch : [11/20] | Step : [40/152]|  Average Training Loss : 15.480623348496565\n",
      "Epoch : [11/20] | Step : [60/152]|  Average Training Loss : 13.801957213731844\n",
      "Epoch : [11/20] | Step : [80/152]|  Average Training Loss : 14.841392472594151\n",
      "Epoch : [11/20] | Step : [100/152]|  Average Training Loss : 14.657056203629631\n",
      "Epoch : [11/20] | Step : [120/152]|  Average Training Loss : 12.21424627578006\n",
      "Epoch : [11/20] | Step : [140/152]|  Average Training Loss : 12.017331714757955\n",
      "Epoch : [11/20] | Step : [20/51]|  Average Validation Loss : 5.616205013820763\n",
      "Epoch : [11/20] | Step : [40/51]|  Average Validation Loss : 4.790259639518536\n",
      "==================================================================================================================================================\n",
      "Epoch : [11/20] | Training Loss : 11.068604378308928, | Validation Loss : 8.477016729807955, | Time consumption: 0:01:03.363265s\n",
      "==================================================================================================================================================\n",
      "Epoch : [12/20] | Step : [20/152]|  Average Training Loss : 18.22773117731831\n",
      "Epoch : [12/20] | Step : [40/152]|  Average Training Loss : 15.480498665370396\n",
      "Epoch : [12/20] | Step : [60/152]|  Average Training Loss : 13.801832261075015\n",
      "Epoch : [12/20] | Step : [80/152]|  Average Training Loss : 14.84128840761033\n",
      "Epoch : [12/20] | Step : [100/152]|  Average Training Loss : 14.656980434055667\n",
      "Epoch : [12/20] | Step : [120/152]|  Average Training Loss : 12.214182726692078\n",
      "Epoch : [12/20] | Step : [140/152]|  Average Training Loss : 12.017278900253594\n",
      "Epoch : [12/20] | Step : [20/51]|  Average Validation Loss : 5.616135471482631\n",
      "Epoch : [12/20] | Step : [40/51]|  Average Validation Loss : 4.790350066086466\n",
      "==================================================================================================================================================\n",
      "Epoch : [12/20] | Training Loss : 11.06856436816086, | Validation Loss : 8.477077062792851, | Time consumption: 0:01:03.644738s\n",
      "==================================================================================================================================================\n",
      "Epoch : [13/20] | Step : [20/152]|  Average Training Loss : 18.22768976113475\n",
      "Epoch : [13/20] | Step : [40/152]|  Average Training Loss : 15.48054650762856\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\mahno\\AppData\\Local\\Temp\\ipykernel_16100\\814893942.py\", line 7, in <module>\n",
      "    train_loss, validation_loss = network.run(dataloaders.train_dataloader, dataloaders.validation_dataloader)\n",
      "  File \"D:\\Repos\\1.11\\seq2point\\seq2point\\seq2point.py\", line 140, in run\n",
      "    train_loss, validation_loss = network_train(self, criterion, optimizer, train_loader, validation_loader)\n",
      "  File \"D:\\Repos\\1.11\\seq2point\\training\\train.py\", line 49, in network_train\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 681, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 721, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"D:\\Repos\\1.11\\seq2point\\dataset_management\\generator.py\", line 31, in __getitem__\n",
      "    return np.array(self.X.iloc[index:index + self.sequence_length]), np.array(self.y.iloc[[index]])\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\pandas\\core\\indexing.py\", line 956, in __getitem__\n",
      "    if type(key) is tuple:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\mahno\\Anaconda\\envs\\torchy\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "dataloaders = Seq2PointDataLoader(target_appliance='kettle', target_houses= {'TRAIN' : [2], 'VALIDATE': [2], 'TEST':[2]}, proportion= {'train_percent':0.6, 'validate_percent':0.3}, subset_days=15)\n",
    "\n",
    "network = SEQ2POINT().to(set_GPU())\n",
    "\n",
    "train_loss, validation_loss = network.run(dataloaders.train_dataloader, dataloaders.validation_dataloader)\n",
    "\n",
    "plot_traces(traces = [train_loss, validation_loss], labels=['training', 'validation'], axis_labels=['Epochs', 'Loss'], title='House 2 Training MAE Loss vs Validation MAE Loss per Epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d0e1e-feab-44d6-9f26-70f0dc0bd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network = SEQ2POINT().to(set_GPU())\n",
    "test_network.inference(dataloaders.test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd754b-5ba0-4e1f-85d4-cb090714b50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
