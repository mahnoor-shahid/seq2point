{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "import builtins\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.GENERAL_CONFIG = get_config_from_json(description=\"General Settings\", config_file=\"configs/general_config.json\")\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73fb4439-9782-4335-b859-567cf977baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7a8ca3-c2dd-4578-ac13-637bca829c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    print(f\"Followings are the {GENERAL_CONFIG['DESCRIPTION']} of your project..\")\n",
    "    pprint(GENERAL_CONFIG)\n",
    "    \n",
    "    ###### random seed selection in progress\n",
    "\n",
    "    random_seed = 10\n",
    "\n",
    "\n",
    "        \n",
    "    model = SEQ2POINT().to(set_GPU())\n",
    "\n",
    "#     train_main,valid_main,train_appliance,valid_appliance = train_test_split(agg, app, test_size=.2, random_state = random_seed)\n",
    "\n",
    "#     train_dataset = TensorDataset(torch.from_numpy(np.array(pd.Series(train_main))).float().permute(0,2,1), torch.from_numpy(np.array(pd.Series(train_main))).float().permute(0,2,1))\n",
    "\n",
    "#     validation_dataset = TensorDataset(torch.from_numpy(valid_main).float().permute(0,2,1), torch.from_numpy(valid_appliance).float().permute(0,2,1))\n",
    "\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                  batch_size=512, # how many samples per batch\n",
    "                                  num_workers=1, # how many subprocesses to use for data loading (higher = more)\n",
    "                                  shuffle=True) # shuffle the data\n",
    "\n",
    "    validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                 batch_size=512, \n",
    "                                 num_workers=1, \n",
    "                                 shuffle=True) # don't need to shuffle testing data\n",
    "    \n",
    "#     train_loss, validation_loss = model.run(train_dataloader, test_dataloader)\n",
    "\n",
    "#     plot_traces(traces = [train_loss, validation_loss], labels=['training', 'validation'], axis_labels=['Epochs', 'Loss'], title='Training Loss vs Validation Loss per Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e3b683c-1afc-4a4a-98eb-1271895b6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the General Settings of your project..\n",
      "{'DATA_PATH': 'data/refit/',\n",
      " 'DESCRIPTION': 'General Settings',\n",
      " 'LOAD_MODEL': '',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SAVE_PATH': 'models/'}\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [24], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m SEQ2POINT()\u001b[38;5;241m.\u001b[39mto(set_GPU())\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     train_main,valid_main,train_appliance,valid_appliance = train_test_split(agg, app, test_size=.2, random_state = random_seed)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#     train_dataset = TensorDataset(torch.from_numpy(np.array(pd.Series(train_main))).float().permute(0,2,1), torch.from_numpy(np.array(pd.Series(train_main))).float().permute(0,2,1))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     validation_dataset = TensorDataset(torch.from_numpy(valid_main).float().permute(0,2,1), torch.from_numpy(valid_appliance).float().permute(0,2,1))\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_data\u001b[49m, \n\u001b[0;32m     22\u001b[0m                                   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, \u001b[38;5;66;03m# how many samples per batch\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                                   num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# how many subprocesses to use for data loading (higher = more)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                                   shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# shuffle the data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     validation_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mvalidation_data, \n\u001b[0;32m     27\u001b[0m                                  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     28\u001b[0m                                  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m     29\u001b[0m                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20168e38-21d4-4499-bed6-7f5563d2d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check libraries and reduce unnecesary\n",
    "#### summaryy writing network summary and torch board summary\n",
    "\n",
    "#### num_workers in loader os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08a1cd9a-3e8b-49d6-897c-0a1ee92e6e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_dataloader\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea72453-abf4-472a-b8be-59753b7461f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
