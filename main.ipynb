{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "from refit_loader.data_loader import REFIT_Loader\n",
    "import builtins\n",
    "import os\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.GENERAL_CONFIG = get_config_from_json(description=\"General Settings\", config_file=\"configs/general_config.json\")\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b9078a-66db-4272-ad91-74ad999eb553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the general configuration of your experiment..\n",
      "{'DATA_FOLDER': 'data/refit/', 'DATA_TYPE': '.csv', 'README_FILE': 'refit_loader/REFIT_Readme.txt', 'REFIT_HOUSES': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]}\n",
      "\n",
      "Loading specified buildings: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "Parsing the readme file specified: refit_loader/REFIT_Readme.txt\n"
     ]
    }
   ],
   "source": [
    "refit = REFIT_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addab95b-34dc-46b7-bc72-927ee627b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for appliance KETTLE ...\n",
      "Fetching KETTLE data for House 2\n",
      "Fetching KETTLE data for House 4\n"
     ]
    }
   ],
   "source": [
    "kettle = refit.get_appliance_data(appliance=\"Kettle\", houses=[2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68243b09-1180-45ac-bc38-9a2fbd7432f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kettle.resample(sampling_period='8s', fill_value=0.0, window_limit=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d259869-0766-4895-91c0-6011d3ca6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kettle.data[2].isnull().sum()\n",
    "# kettle.data[2].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffb98d1-5d65-4c48-a58f-8deab4e6e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class DataGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.sequence_length = MODEL_CONFIG['SEQUENCE_LENGTH']\n",
    "        # assert self.sequence_length >= 599, f\"Provided sequence length is {self.sequence_length} while it should be atleast >=599\"\n",
    "        \n",
    "        lst = [0] * 599        \n",
    "        self.time = data.index\n",
    "        self.X = data['aggregate'] \n",
    "\n",
    "        self.y =  data[data.columns[-1]] \n",
    "#         self.X = pd.concat([ data['aggregate'] , pd.Series(lst)])\n",
    "\n",
    "#         self.y = pd.concat([ data[data.columns[-1]] , pd.Series(lst)])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.time)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        mid = int(index + (self.sequence_length/2))\n",
    "        \n",
    "        if index + self.sequence_length > len(self.time) and mid > len(self.time):\n",
    "            print('not valid')\n",
    "            # print(torch.tensor(self.X.iloc[index:index + self.sequence_length]), torch.tensor(self.y.iloc[[mid]]))\n",
    "        return (torch.tensor(self.X.iloc[index:index + self.sequence_length]), torch.tensor(self.y.iloc[[mid]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7a8ca3-c2dd-4578-ac13-637bca829c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(train_data, validation_data):\n",
    "    \n",
    "    print(f\"Followings are the {GENERAL_CONFIG['DESCRIPTION']} of your project..\")\n",
    "    pprint(GENERAL_CONFIG)\n",
    "    \n",
    "    ###### random seed selection in progress\n",
    "\n",
    "    random_seed = 10\n",
    "\n",
    "    network = SEQ2POINT().to(set_GPU())\n",
    "\n",
    "    train_generator = DataGenerator(train_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset=train_generator, \n",
    "                                                  batch_size=TRAINING_CONFIG['TRAIN_BATCH_SIZE'], # how many samples per batch\n",
    "                                                  num_workers=0, # how many subprocesses to use for data loading (higher = more)\n",
    "                                                  shuffle=False) # shuffle the data\n",
    "    \n",
    "    validation_generator = DataGenerator(validation_data)\n",
    "    \n",
    "    validation_dataloader = torch.utils.data.DataLoader(dataset=validation_generator, \n",
    "                                                  batch_size=TRAINING_CONFIG['TRAIN_BATCH_SIZE'], # how many samples per batch\n",
    "                                                  num_workers=0, # how many subprocesses to use for data loading (higher = more)\n",
    "                                                  shuffle=False) # shuffle the data    \n",
    "\n",
    "    \n",
    "    train_loss, validation_loss = network.run(train_dataloader, validation_dataloader)\n",
    "\n",
    "    plot_traces(traces = [train_loss, validation_loss], labels=['training', 'validation'], axis_labels=['Epochs', 'Loss'], title='Training Loss vs Validation Loss per Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea72453-abf4-472a-b8be-59753b7461f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the General Settings of your project..\n",
      "{'DATA_PATH': 'data/refit/',\n",
      " 'DESCRIPTION': 'General Settings',\n",
      " 'LOAD_MODEL': '',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SAVE_PATH': 'models/'}\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n",
      "\n",
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 3,\n",
      " 'LEARNING_RATE': 0.001,\n",
      " 'LOSS': 'nn.MSELoss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NUM_EPOCHS': 5,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'TRAIN_BATCH_SIZE': 64}\n",
      "\n",
      "Summary of the model architecture\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 50, 599]             12,550\n",
      "|    └─ReLU: 2-15                        [-1, 50, 599]             --\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─Linear: 2-16                      [-1, 1024]                30,669,824\n",
      "|    └─ReLU: 2-17                        [-1, 1024]                --\n",
      "|    └─Linear: 2-18                      [-1, 1]                   1,025\n",
      "==========================================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 83.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 117.14\n",
      "Estimated Total Size (MB): 118.07\n",
      "==========================================================================================\n",
      "\n",
      "Training the model architecture...\n",
      "16\n",
      "0\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "16\n",
      "1\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "16\n",
      "2\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "16\n",
      "3\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "16\n",
      "4\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "16\n",
      "5\n",
      "data\n",
      "torch.Size([64, 1, 599])\n",
      "targets\n",
      "torch.Size([64, 1, 1])\n",
      "predictions\n",
      "torch.Size([64, 1, 1])\n",
      "Error occured in network_training method due to  stack expects each tensor to be equal size, but got [599] at entry 0 and [598] at entry 18\n",
      "Error occured in run wrapper method due to  cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [13], line 27\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(train_data, validation_data)\u001b[0m\n\u001b[0;32m     19\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m DataGenerator(validation_data)\n\u001b[0;32m     21\u001b[0m validation_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mvalidation_generator, \n\u001b[0;32m     22\u001b[0m                                               batch_size\u001b[38;5;241m=\u001b[39mTRAINING_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN_BATCH_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# how many samples per batch\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                                               num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;66;03m# how many subprocesses to use for data loading (higher = more)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m                                               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# shuffle the data    \u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m train_loss, validation_loss \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mrun(train_dataloader, validation_dataloader)\n\u001b[0;32m     29\u001b[0m plot_traces(traces \u001b[38;5;241m=\u001b[39m [train_loss, validation_loss], labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m], axis_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m], title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss vs Validation Loss per Epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "main(train_data = kettle.data[2].iloc[2000:3000], validation_data = kettle.data[4].iloc[2000:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13b6d2-9e26-42c3-a6ad-997f087f25f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
