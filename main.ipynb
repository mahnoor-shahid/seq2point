{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU, initialize_weights, set_criterion, set_optimization\n",
    "from train.train import network_training\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "import builtins\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.GENERAL_CONFIG = get_config_from_json(description=\"General Settings\", config_file=\"configs/general_config.json\")\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac3ef32-5253-457e-b8bd-27aba5b220d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the Model Parameters of your experiment..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': [0],\n",
      " 'CONV_STRIDE': [1],\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n"
     ]
    }
   ],
   "source": [
    "model = SEQ2POINT().to(set_GPU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d618ee-50cb-449c-bf7f-9fdf3f4a53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtins.model_config = configuration.get_config_from_json(description=\"Model Configuration\", config_file=\"configs/model_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "834eb97e-dbe6-486b-a3fd-5b61acf56d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 3,\n",
      " 'LEARNING_RATE': 0.001,\n",
      " 'LOSS': 'nn.MSELoss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NUM_EPOCHS': 10,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'TRAIN_BATCH_SIZE': 64}\n",
      "Error occured in forward method due to  mat1 and mat2 shapes cannot be multiplied (60x599 and 29950x1024)\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        []                        --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 30, 599]             7,530\n",
      "|    └─ReLU: 2-15                        [-1, 30, 599]             --\n",
      "|    └─Linear: 2-16                      []                        30,669,824\n",
      "==========================================================================================\n",
      "Total params: 30,702,204\n",
      "Trainable params: 30,702,204\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 19.29\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.82\n",
      "Params size (MB): 117.12\n",
      "Estimated Total Size (MB): 117.94\n",
      "==========================================================================================\n",
      "Error occured in network_training method due to  name 'training_config' is not defined\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     13\u001b[0m     validation_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     train_loss, validation_loss \u001b[38;5;241m=\u001b[39m network_training()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m GENERAL_SETTINGS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRE_TRAINED_MODEL_FLAG\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_model() \u001b[38;5;66;03m## in progress\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "if GENERAL_CONFIG['PRE_TRAINED_MODEL_FLAG'] == False:\n",
    "    \n",
    "    print(f\"Followings are the {TRAINING_CONFIG['DESCRIPTION']} of your experiment..\")\n",
    "    pprint(TRAINING_CONFIG)\n",
    "    \n",
    "    model.apply(initialize_weights) \n",
    "    summary(model, (1,599)) ## in progress\n",
    "\n",
    "    criterion = set_criterion()\n",
    "    optimizer = set_optimization(model)\n",
    "\n",
    "    train_loader = torch.randn(5,2)\n",
    "    validation_loader = torch.randn(2,2)\n",
    "\n",
    "    train_loss, validation_loss = network_training()\n",
    "\n",
    "elif GENERAL_SETTINGS['PRE_TRAINED_MODEL_FLAG'] == True:\n",
    "    model.load_model() ## in progress\n",
    "    summary(model, (1,599)) ## in progress\n",
    "    \n",
    "else:\n",
    "    raise Exception('In configs/general_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8cb76-1c95-44bd-abdd-2804dca35949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566893f-1015-4507-9309-4cca6941481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82deae56-4002-446d-bf63-3bb7bd51abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796750a-dde0-494d-837a-dfe8996a5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({'Training Loss':train_loss, 'Validation Loss':validation_loss})\n",
    "df.plot(linewidth=4, alpha=0.7, figsize=(12,7), label='Loss')\n",
    "plt.xlim([0,10])\n",
    "# plt.ylim(-20,100)\n",
    "plt.title('Training Loss vs Validation Loss per Epoch', fontsize=20)\n",
    "plt.grid(axis='y', alpha=.5)\n",
    "plt.yticks(fontsize=12, alpha=.7)\n",
    "plt.xticks(fontsize=12, alpha=.7)\n",
    "plt.xlabel('Epoch', fontsize=18, alpha=.7)\n",
    "plt.ylabel('Loss Value', fontsize=18, alpha=.7)\n",
    "# Lighten borders\n",
    "plt.gca().spines[\"top\"].set_alpha(.0)\n",
    "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(.0)\n",
    "plt.gca().spines[\"left\"].set_alpha(.3)\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78144cae-5fa1-4e64-acba-b7664aefe06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da4611-c9c4-49b8-92f4-738bf3b4851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2a2a7-0b28-4170-a7b0-1bf74fea1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"nn.MSELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc3206-e980-42db-94e0-d02ee2122a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265fe6-2f9a-4aec-950d-e7474a16ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956b0b4-e5e0-4fea-95c2-fe5b74b70874",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7af85-e8ea-4274-afa4-1183d41042a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    pass\n",
    "\n",
    "str_to_class(\"nn.MSE()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6550d4-27d6-4347-b5e1-beb4c0d1736c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
