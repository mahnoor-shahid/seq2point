{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "from refit_loader.data_loader import REFIT_Loader\n",
    "from dataset_management.dataloader import Seq2PointDataLoader\n",
    "import builtins\n",
    "import os\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.DATASET_CONFIG = get_config_from_json(description=\"Dataset Management\", config_file=\"configs/dataset_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a8ca3-c2dd-4578-ac13-637bca829c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the refit_loader configuration \n",
      "{'DATA_FOLDER': 'data/refit/', 'DATA_TYPE': '.csv', 'README_FILE': 'refit_loader/REFIT_Readme.txt', 'REFIT_HOUSES': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]}\n",
      "\n",
      "Loading specified buildings: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "Parsing the readme file specified: refit_loader/REFIT_Readme.txt\n",
      "Loading data for appliance KETTLE ...\n",
      "Fetching KETTLE data for House 2\n",
      "Resampling for house number:  2\n",
      "Creating 10 smaller subsets from complete dataset of House 2\n",
      "Estimating active durations of: kettle\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n",
      "\n",
      "\n",
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 5,\n",
      " 'LEARNING_RATE': 0.001,\n",
      " 'LOAD_MODEL': 'models/best_model/2022-11-16_best_loss_38102.pt',\n",
      " 'LOSS': 'nn.MSELoss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NUM_EPOCHS': 20,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SAVE_MODEL': 'models/',\n",
      " 'TEST_BATCH_SIZE': 512,\n",
      " 'TRAIN_BATCH_SIZE': 512,\n",
      " 'VALIDATION_BATCH_SIZE': 512}\n",
      "\n",
      "Summary of the model architecture\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 50, 599]             12,550\n",
      "|    └─ReLU: 2-15                        [-1, 50, 599]             --\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─Linear: 2-16                      [-1, 1024]                30,669,824\n",
      "|    └─ReLU: 2-17                        [-1, 1024]                --\n",
      "|    └─Linear: 2-18                      [-1, 1]                   1,025\n",
      "==========================================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 83.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 117.14\n",
      "Estimated Total Size (MB): 118.07\n",
      "==========================================================================================\n",
      "SEQ2POINT(\n",
      "  (conv): Sequential(\n",
      "    (0): ConstantPad1d(padding=(4, 5), value=0)\n",
      "    (1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConstantPad1d(padding=(3, 4), value=0)\n",
      "    (4): Conv1d(30, 30, kernel_size=(8,), stride=(1,))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConstantPad1d(padding=(2, 3), value=0)\n",
      "    (7): Conv1d(30, 40, kernel_size=(6,), stride=(1,))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConstantPad1d(padding=(2, 2), value=0)\n",
      "    (10): Conv1d(40, 50, kernel_size=(5,), stride=(1,))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConstantPad1d(padding=(2, 2), value=0)\n",
      "    (13): Conv1d(50, 50, kernel_size=(5,), stride=(1,))\n",
      "    (14): ReLU(inplace=True)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=29950, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Training the model architecture...\n",
      "Epoch : [1/20] | Step : [20/148]|  Average Training Loss : 418878.4428253174\n",
      "Epoch : [1/20] | Step : [40/148]|  Average Training Loss : 255368.8065759659\n",
      "Epoch : [1/20] | Step : [60/148]|  Average Training Loss : 189683.25637397767\n",
      "Epoch : [1/20] | Step : [80/148]|  Average Training Loss : 142375.97192964554\n",
      "Epoch : [1/20] | Step : [100/148]|  Average Training Loss : 120982.70294494828\n",
      "Epoch : [1/20] | Step : [120/148]|  Average Training Loss : 100818.919209366\n",
      "Epoch : [1/20] | Step : [140/148]|  Average Training Loss : 88605.39983471557\n",
      "Epoch : [1/20] | Step : [20/43]|  Average Validation Loss : 147696.41168550015\n",
      "Epoch : [1/20] | Step : [40/43]|  Average Validation Loss : 102650.732208535\n",
      "==================================================================================================================================================\n",
      "Epoch : [0/20] | Training Loss : 85238.88566034033, | Validation Loss : 95489.05325988511, | Time consumption: 0:01:05.380286s\n",
      "Epoch : [2/20] | Step : [20/148]|  Average Training Loss : 28648.086175039054\n",
      "Epoch : [2/20] | Step : [40/148]|  Average Training Loss : 41734.035665475916\n",
      "Epoch : [2/20] | Step : [60/148]|  Average Training Loss : 37554.84046126294\n",
      "Epoch : [2/20] | Step : [80/148]|  Average Training Loss : 28166.130363097287\n",
      "Epoch : [2/20] | Step : [100/148]|  Average Training Loss : 28380.085320248796\n",
      "Epoch : [2/20] | Step : [120/148]|  Average Training Loss : 23650.08160126683\n",
      "Epoch : [2/20] | Step : [140/148]|  Average Training Loss : 22457.267748554565\n",
      "Epoch : [2/20] | Step : [20/43]|  Average Validation Loss : 145593.06058035567\n",
      "Epoch : [2/20] | Step : [40/43]|  Average Validation Loss : 101335.67477817871\n",
      "==================================================================================================================================================\n",
      "Epoch : [1/20] | Training Loss : 22664.700688692872, | Validation Loss : 94266.50170694153, | Time consumption: 0:01:04.172259s\n",
      "Saving the 2022-11-17_best_loss_94267 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [3/20] | Step : [20/148]|  Average Training Loss : 29270.32195774913\n",
      "Epoch : [3/20] | Step : [40/148]|  Average Training Loss : 41858.60878480375\n",
      "Epoch : [3/20] | Step : [60/148]|  Average Training Loss : 37591.8718085587\n",
      "Epoch : [3/20] | Step : [80/148]|  Average Training Loss : 28194.22719469974\n",
      "Epoch : [3/20] | Step : [100/148]|  Average Training Loss : 28124.9776756946\n",
      "Epoch : [3/20] | Step : [120/148]|  Average Training Loss : 23438.719091537907\n",
      "Epoch : [3/20] | Step : [140/148]|  Average Training Loss : 22286.052762760242\n",
      "Epoch : [3/20] | Step : [20/43]|  Average Validation Loss : 143447.46708750128\n",
      "Epoch : [3/20] | Step : [40/43]|  Average Validation Loss : 100464.36069180668\n",
      "==================================================================================================================================================\n",
      "Epoch : [2/20] | Training Loss : 22460.292378455622, | Validation Loss : 93457.21126234531, | Time consumption: 0:01:02.096155s\n",
      "Saving the 2022-11-17_best_loss_93457 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [4/20] | Step : [20/148]|  Average Training Loss : 28458.74275584221\n",
      "Epoch : [4/20] | Step : [40/148]|  Average Training Loss : 40257.40488715768\n",
      "Epoch : [4/20] | Step : [60/148]|  Average Training Loss : 36166.97934003274\n",
      "Epoch : [4/20] | Step : [80/148]|  Average Training Loss : 27130.877301457524\n",
      "Epoch : [4/20] | Step : [100/148]|  Average Training Loss : 27284.367395450474\n",
      "Epoch : [4/20] | Step : [120/148]|  Average Training Loss : 22738.424528355896\n",
      "Epoch : [4/20] | Step : [140/148]|  Average Training Loss : 21768.055666472792\n",
      "Epoch : [4/20] | Step : [20/43]|  Average Validation Loss : 140687.7760297671\n",
      "Epoch : [4/20] | Step : [40/43]|  Average Validation Loss : 98441.88711716607\n",
      "==================================================================================================================================================\n",
      "Epoch : [3/20] | Training Loss : 21905.24244439172, | Validation Loss : 91574.429240111, | Time consumption: 0:01:05.112826s\n",
      "Saving the 2022-11-17_best_loss_91574 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [5/20] | Step : [20/148]|  Average Training Loss : 29597.045482641457\n",
      "Epoch : [5/20] | Step : [40/148]|  Average Training Loss : 39346.22772617638\n",
      "Epoch : [5/20] | Step : [60/148]|  Average Training Loss : 34617.25051957965\n",
      "Epoch : [5/20] | Step : [80/148]|  Average Training Loss : 25963.441994218156\n",
      "Epoch : [5/20] | Step : [100/148]|  Average Training Loss : 25273.64079072982\n",
      "Epoch : [5/20] | Step : [120/148]|  Average Training Loss : 21061.78256054148\n",
      "Epoch : [5/20] | Step : [140/148]|  Average Training Loss : 20905.133419229776\n",
      "Epoch : [5/20] | Step : [20/43]|  Average Validation Loss : 141960.8543590337\n",
      "Epoch : [5/20] | Step : [40/43]|  Average Validation Loss : 99784.0621028915\n",
      "==================================================================================================================================================\n",
      "Epoch : [4/20] | Training Loss : 21054.64788383129, | Validation Loss : 92822.48813953095, | Time consumption: 0:01:02.980150s\n",
      "Epoch : [6/20] | Step : [20/148]|  Average Training Loss : 29200.10157725215\n",
      "Epoch : [6/20] | Step : [40/148]|  Average Training Loss : 40715.248157188296\n",
      "Epoch : [6/20] | Step : [60/148]|  Average Training Loss : 35973.68420461615\n",
      "Epoch : [6/20] | Step : [80/148]|  Average Training Loss : 26983.58488932699\n",
      "Epoch : [6/20] | Step : [100/148]|  Average Training Loss : 25492.94084513068\n",
      "Epoch : [6/20] | Step : [120/148]|  Average Training Loss : 21244.221651476437\n",
      "Epoch : [6/20] | Step : [140/148]|  Average Training Loss : 20947.628049245017\n",
      "Epoch : [6/20] | Step : [20/43]|  Average Validation Loss : 145570.10051808954\n",
      "Epoch : [6/20] | Step : [40/43]|  Average Validation Loss : 100940.48967422693\n",
      "==================================================================================================================================================\n",
      "Epoch : [5/20] | Training Loss : 21117.13111427423, | Validation Loss : 93898.6933931237, | Time consumption: 0:01:03.600761s\n",
      "Epoch : [7/20] | Step : [20/148]|  Average Training Loss : 28180.007902535795\n",
      "Epoch : [7/20] | Step : [40/148]|  Average Training Loss : 40150.33534886092\n",
      "Epoch : [7/20] | Step : [60/148]|  Average Training Loss : 36629.30580162505\n",
      "Epoch : [7/20] | Step : [80/148]|  Average Training Loss : 27491.10046590194\n",
      "Epoch : [7/20] | Step : [100/148]|  Average Training Loss : 27645.252608899475\n",
      "Epoch : [7/20] | Step : [120/148]|  Average Training Loss : 23037.921558847527\n",
      "Epoch : [7/20] | Step : [140/148]|  Average Training Loss : 22006.524913878606\n",
      "Epoch : [7/20] | Step : [20/43]|  Average Validation Loss : 142846.4915111769\n",
      "Epoch : [7/20] | Step : [40/43]|  Average Validation Loss : 99586.20870302152\n",
      "==================================================================================================================================================\n",
      "Epoch : [6/20] | Training Loss : 22120.593224135682, | Validation Loss : 92638.35806286595, | Time consumption: 0:01:05.843620s\n",
      "Saving the 2022-11-17_best_loss_92638 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [8/20] | Step : [20/148]|  Average Training Loss : 27724.889328042977\n",
      "Epoch : [8/20] | Step : [40/148]|  Average Training Loss : 36952.99545099949\n",
      "Epoch : [8/20] | Step : [60/148]|  Average Training Loss : 31454.22937772417\n",
      "Epoch : [8/20] | Step : [80/148]|  Average Training Loss : 23594.581572140334\n",
      "Epoch : [8/20] | Step : [100/148]|  Average Training Loss : 23431.975274150038\n",
      "Epoch : [8/20] | Step : [120/148]|  Average Training Loss : 19529.249139648397\n",
      "Epoch : [8/20] | Step : [140/148]|  Average Training Loss : 20181.46642826173\n",
      "Epoch : [8/20] | Step : [20/43]|  Average Validation Loss : 146586.31437922386\n",
      "Epoch : [8/20] | Step : [40/43]|  Average Validation Loss : 101653.86413445428\n",
      "==================================================================================================================================================\n",
      "Epoch : [7/20] | Training Loss : 20475.95561251865, | Validation Loss : 94561.85729006896, | Time consumption: 0:01:04.896308s\n",
      "Epoch : [9/20] | Step : [20/148]|  Average Training Loss : 29081.928645068918\n",
      "Epoch : [9/20] | Step : [40/148]|  Average Training Loss : 42576.8465218636\n",
      "Epoch : [9/20] | Step : [60/148]|  Average Training Loss : 37922.093793185784\n",
      "Epoch : [9/20] | Step : [80/148]|  Average Training Loss : 28441.664397398\n",
      "Epoch : [9/20] | Step : [100/148]|  Average Training Loss : 28102.641247743657\n",
      "Epoch : [9/20] | Step : [120/148]|  Average Training Loss : 23421.99145328526\n",
      "Epoch : [9/20] | Step : [140/148]|  Average Training Loss : 22245.72755968243\n",
      "Epoch : [9/20] | Step : [20/43]|  Average Validation Loss : 143810.6785679087\n",
      "Epoch : [9/20] | Step : [40/43]|  Average Validation Loss : 100282.7362098828\n",
      "==================================================================================================================================================\n",
      "Epoch : [8/20] | Training Loss : 22333.01296428301, | Validation Loss : 93286.2822107593, | Time consumption: 0:01:04.673880s\n",
      "Saving the 2022-11-17_best_loss_93286 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [10/20] | Step : [20/148]|  Average Training Loss : 27712.220528002083\n",
      "Epoch : [10/20] | Step : [40/148]|  Average Training Loss : 39406.64956873283\n",
      "Epoch : [10/20] | Step : [60/148]|  Average Training Loss : 35010.189497121675\n",
      "Epoch : [10/20] | Step : [80/148]|  Average Training Loss : 26257.695309197043\n",
      "Epoch : [10/20] | Step : [100/148]|  Average Training Loss : 24957.2961997185\n",
      "Epoch : [10/20] | Step : [120/148]|  Average Training Loss : 20797.913353834618\n",
      "Epoch : [10/20] | Step : [140/148]|  Average Training Loss : 20612.481791449292\n",
      "Epoch : [10/20] | Step : [20/43]|  Average Validation Loss : 144226.83577314008\n",
      "Epoch : [10/20] | Step : [40/43]|  Average Validation Loss : 100427.86253771346\n",
      "==================================================================================================================================================\n",
      "Epoch : [9/20] | Training Loss : 20734.11432668552, | Validation Loss : 93421.26787862374, | Time consumption: 0:01:05.865695s\n",
      "Epoch : [11/20] | Step : [20/148]|  Average Training Loss : 28302.448519554117\n",
      "Epoch : [11/20] | Step : [40/148]|  Average Training Loss : 38823.82018661282\n",
      "Epoch : [11/20] | Step : [60/148]|  Average Training Loss : 32958.682595968705\n",
      "Epoch : [11/20] | Step : [80/148]|  Average Training Loss : 24723.036115980496\n",
      "Epoch : [11/20] | Step : [100/148]|  Average Training Loss : 29720.75789762495\n",
      "Epoch : [11/20] | Step : [120/148]|  Average Training Loss : 24771.68832249789\n",
      "Epoch : [11/20] | Step : [140/148]|  Average Training Loss : 27063.07838040867\n",
      "Epoch : [11/20] | Step : [20/43]|  Average Validation Loss : 147406.683529675\n",
      "Epoch : [11/20] | Step : [40/43]|  Average Validation Loss : 103973.901247859\n",
      "==================================================================================================================================================\n",
      "Epoch : [10/20] | Training Loss : 27218.098766687956, | Validation Loss : 96720.59639257609, | Time consumption: 0:01:08.049905s\n",
      "Epoch : [12/20] | Step : [20/148]|  Average Training Loss : 27686.450458087398\n",
      "Epoch : [12/20] | Step : [40/148]|  Average Training Loss : 43925.544773037174\n",
      "Epoch : [12/20] | Step : [60/148]|  Average Training Loss : 39007.97194063328\n",
      "Epoch : [12/20] | Step : [80/148]|  Average Training Loss : 29256.84069231944\n",
      "Epoch : [12/20] | Step : [100/148]|  Average Training Loss : 28919.180041271822\n",
      "Epoch : [12/20] | Step : [120/148]|  Average Training Loss : 24109.16206871004\n",
      "Epoch : [12/20] | Step : [140/148]|  Average Training Loss : 22860.38416720052\n",
      "Epoch : [12/20] | Step : [20/43]|  Average Validation Loss : 145013.28769696242\n",
      "Epoch : [12/20] | Step : [40/43]|  Average Validation Loss : 101132.66363416796\n",
      "==================================================================================================================================================\n",
      "Epoch : [11/20] | Training Loss : 22967.954436058713, | Validation Loss : 94076.94991058974, | Time consumption: 0:01:06.603516s\n",
      "Saving the 2022-11-17_best_loss_94077 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [13/20] | Step : [20/148]|  Average Training Loss : 27220.252541322912\n",
      "Epoch : [13/20] | Step : [40/148]|  Average Training Loss : 42226.20864795218\n",
      "Epoch : [13/20] | Step : [60/148]|  Average Training Loss : 37873.17895257619\n",
      "Epoch : [13/20] | Step : [80/148]|  Average Training Loss : 28413.357417542837\n",
      "Epoch : [13/20] | Step : [100/148]|  Average Training Loss : 28083.838963864724\n",
      "Epoch : [13/20] | Step : [120/148]|  Average Training Loss : 23404.54532877677\n",
      "Epoch : [13/20] | Step : [140/148]|  Average Training Loss : 22211.371975658236\n",
      "Epoch : [13/20] | Step : [20/43]|  Average Validation Loss : 143443.87421157063\n",
      "Epoch : [13/20] | Step : [40/43]|  Average Validation Loss : 99947.50770709664\n",
      "==================================================================================================================================================\n",
      "Epoch : [12/20] | Training Loss : 22358.391235624655, | Validation Loss : 92974.50522468533, | Time consumption: 0:01:08.210408s\n",
      "Saving the 2022-11-17_best_loss_92975 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [14/20] | Step : [20/148]|  Average Training Loss : 27374.064150063692\n",
      "Epoch : [14/20] | Step : [40/148]|  Average Training Loss : 39569.175594814864\n",
      "Epoch : [14/20] | Step : [60/148]|  Average Training Loss : 36143.73355083253\n",
      "Epoch : [14/20] | Step : [80/148]|  Average Training Loss : 27107.801141275006\n",
      "Epoch : [14/20] | Step : [100/148]|  Average Training Loss : 26897.399950390514\n",
      "Epoch : [14/20] | Step : [120/148]|  Average Training Loss : 22415.200745440445\n",
      "Epoch : [14/20] | Step : [140/148]|  Average Training Loss : 21644.232546544536\n",
      "Epoch : [14/20] | Step : [20/43]|  Average Validation Loss : 144986.3514039576\n",
      "Epoch : [14/20] | Step : [40/43]|  Average Validation Loss : 101000.26313662976\n",
      "==================================================================================================================================================\n",
      "Epoch : [13/20] | Training Loss : 21801.552391728266, | Validation Loss : 93953.75250983308, | Time consumption: 0:01:08.369800s\n",
      "Epoch : [15/20] | Step : [20/148]|  Average Training Loss : 27557.189670838394\n",
      "Epoch : [15/20] | Step : [40/148]|  Average Training Loss : 38635.54858663081\n",
      "Epoch : [15/20] | Step : [60/148]|  Average Training Loss : 35183.26484264259\n",
      "Epoch : [15/20] | Step : [80/148]|  Average Training Loss : 26387.792442971277\n",
      "Epoch : [15/20] | Step : [100/148]|  Average Training Loss : 25896.93387867756\n",
      "Epoch : [15/20] | Step : [120/148]|  Average Training Loss : 21580.856855785718\n",
      "Epoch : [15/20] | Step : [140/148]|  Average Training Loss : 20911.88955890956\n",
      "Epoch : [15/20] | Step : [20/43]|  Average Validation Loss : 143219.85034673102\n",
      "Epoch : [15/20] | Step : [40/43]|  Average Validation Loss : 99690.68060283238\n",
      "==================================================================================================================================================\n",
      "Epoch : [14/20] | Training Loss : 21058.083282406813, | Validation Loss : 92735.53543384525, | Time consumption: 0:01:08.464989s\n",
      "Saving the 2022-11-17_best_loss_92736 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [16/20] | Step : [20/148]|  Average Training Loss : 26571.635296380402\n",
      "Epoch : [16/20] | Step : [40/148]|  Average Training Loss : 36466.25192479197\n",
      "Epoch : [16/20] | Step : [60/148]|  Average Training Loss : 30808.837193816456\n",
      "Epoch : [16/20] | Step : [80/148]|  Average Training Loss : 23106.662511100625\n",
      "Epoch : [16/20] | Step : [100/148]|  Average Training Loss : 25095.495594739135\n",
      "Epoch : [16/20] | Step : [120/148]|  Average Training Loss : 20912.914717304557\n",
      "Epoch : [16/20] | Step : [140/148]|  Average Training Loss : 20038.786989200617\n",
      "Epoch : [16/20] | Step : [20/43]|  Average Validation Loss : 144189.5794173908\n",
      "Epoch : [16/20] | Step : [40/43]|  Average Validation Loss : 100764.30958974139\n",
      "==================================================================================================================================================\n",
      "Epoch : [15/20] | Training Loss : 20227.49580248382, | Validation Loss : 93734.26816977728, | Time consumption: 0:01:05.228717s\n",
      "Epoch : [17/20] | Step : [20/148]|  Average Training Loss : 26191.603970519187\n",
      "Epoch : [17/20] | Step : [40/148]|  Average Training Loss : 36140.817568453596\n",
      "Epoch : [17/20] | Step : [60/148]|  Average Training Loss : 30469.053015692396\n",
      "Epoch : [17/20] | Step : [80/148]|  Average Training Loss : 22856.77467591864\n",
      "Epoch : [17/20] | Step : [100/148]|  Average Training Loss : 24837.034373883223\n",
      "Epoch : [17/20] | Step : [120/148]|  Average Training Loss : 20699.36236455359\n",
      "Epoch : [17/20] | Step : [140/148]|  Average Training Loss : 20493.52993524936\n",
      "Epoch : [17/20] | Step : [20/43]|  Average Validation Loss : 145486.14766783174\n",
      "Epoch : [17/20] | Step : [40/43]|  Average Validation Loss : 101338.53129602615\n",
      "==================================================================================================================================================\n",
      "Epoch : [16/20] | Training Loss : 20777.661109780434, | Validation Loss : 94268.4232731567, | Time consumption: 0:01:05.319278s\n",
      "Epoch : [18/20] | Step : [20/148]|  Average Training Loss : 26011.257155642284\n",
      "Epoch : [18/20] | Step : [40/148]|  Average Training Loss : 38918.82253607533\n",
      "Epoch : [18/20] | Step : [60/148]|  Average Training Loss : 34852.66508901462\n",
      "Epoch : [18/20] | Step : [80/148]|  Average Training Loss : 26139.508807037317\n",
      "Epoch : [18/20] | Step : [100/148]|  Average Training Loss : 25809.759892124413\n",
      "Epoch : [18/20] | Step : [120/148]|  Average Training Loss : 21508.222784691512\n",
      "Epoch : [18/20] | Step : [140/148]|  Average Training Loss : 20684.794704740074\n",
      "Epoch : [18/20] | Step : [20/43]|  Average Validation Loss : 141591.14219363453\n",
      "Epoch : [18/20] | Step : [40/43]|  Average Validation Loss : 99871.28332692327\n",
      "==================================================================================================================================================\n",
      "Epoch : [17/20] | Training Loss : 20873.930572598474, | Validation Loss : 92903.66927788734, | Time consumption: 0:01:04.392004s\n",
      "Saving the 2022-11-17_best_loss_92904 model to models/best_model/2022-11-16_best_loss_38102.pt\n",
      "Epoch : [19/20] | Step : [20/148]|  Average Training Loss : 24590.7198684711\n",
      "Epoch : [19/20] | Step : [40/148]|  Average Training Loss : 34692.86757919546\n",
      "Epoch : [19/20] | Step : [60/148]|  Average Training Loss : 32227.896262997885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "dataloaders = Seq2PointDataLoader(target_appliance='kettle', target_houses= {'TRAIN' : [2], 'VALIDATE': [2], 'TEST':[2]}, proportion= {'train_percent':0.7, 'validate_percent':0.2}, subset_days=10)\n",
    "\n",
    "network = SEQ2POINT().to(set_GPU())\n",
    "\n",
    "train_loss, validation_loss = network.run(dataloaders.train_dataloader, dataloaders.validation_dataloader)\n",
    "\n",
    "plot_traces(traces = [train_loss, validation_loss], labels=['training', 'validation'], axis_labels=['Epochs', 'Loss'], title='Training MSE Loss vs Validation MSE Loss per Epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d0e1e-feab-44d6-9f26-70f0dc0bd2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network = SEQ2POINT().to(set_GPU())\n",
    "test_network.inference(dataloaders.test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd754b-5ba0-4e1f-85d4-cb090714b50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
