{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fad2a-38fa-4ad3-ad23-1bb9f5100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.configuration import get_config_from_json\n",
    "from utils.training_utilities import set_GPU\n",
    "from utils.plotting_traces import plot_traces\n",
    "from seq2point.seq2point import SEQ2POINT\n",
    "import builtins\n",
    "from pprint import pprint\n",
    "\n",
    "builtins.GENERAL_CONFIG = get_config_from_json(description=\"General Settings\", config_file=\"configs/general_config.json\")\n",
    "builtins.MODEL_CONFIG = get_config_from_json(description=\"Model Parameters\", config_file=\"configs/model_config.json\")\n",
    "builtins.TRAINING_CONFIG = get_config_from_json(description=\"Training Configuration\", config_file=\"configs/training_config.json\")\n",
    "builtins.PLOT_CONFIG = get_config_from_json(description=\"Plot Settings\", config_file=\"configs/plot_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fb4439-9782-4335-b859-567cf977baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import torch\n",
    "from refit_loader.data_loader import REFIT_Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b9078a-66db-4272-ad91-74ad999eb553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the general configuration of your experiment..\n",
      "{'DATA_FOLDER': 'data/refit/', 'DATA_TYPE': '.csv', 'README_FILE': 'refit_loader/REFIT_Readme.txt', 'REFIT_HOUSES': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]}\n",
      "\n",
      "Loading specified buildings: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "Parsing the readme file specified: refit_loader/REFIT_Readme.txt\n"
     ]
    }
   ],
   "source": [
    "refit = REFIT_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addab95b-34dc-46b7-bc72-927ee627b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for appliance KETTLE ...\n",
      "Fetching KETTLE data for House 2\n"
     ]
    }
   ],
   "source": [
    "kettle = refit.get_appliance_data(appliance=\"Kettle\", houses=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68243b09-1180-45ac-bc38-9a2fbd7432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling for house number:  2\n"
     ]
    }
   ],
   "source": [
    "kettle.resample(sampling_period='8s', fill_value=0.0, window_limit=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30175dcb-816c-4748-8eb3-78ae58cb39d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kettle.data[2].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c44df38-a695-4d11-82ae-9622fd94f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kettle.data[2].isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1fef384-ab9f-4fd9-b3d3-b1aaeb6b42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# len(np.array(kettle.data[2]['aggregate'][:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b360e2-48c4-46cc-9c1d-547a2621b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import DataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8968578d-2467-434a-bc6b-fb8bb8f5eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= np.array(kettle.data[2]['aggregate'][0:10000])\n",
    "train_y= np.array(kettle.data[2]['kettle'][0:10000] )\n",
    "validate_x= np.array(kettle.data[2]['aggregate'][0:10000])\n",
    "validate_y= np.array(kettle.data[2]['kettle'][0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c7a8ca3-c2dd-4578-ac13-637bca829c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(train_x, train_y, validate_x, validate_y):\n",
    "    \n",
    "    print(f\"Followings are the {GENERAL_CONFIG['DESCRIPTION']} of your project..\")\n",
    "    pprint(GENERAL_CONFIG)\n",
    "    \n",
    "    ###### random seed selection in progress\n",
    "\n",
    "    random_seed = 10\n",
    "\n",
    "\n",
    "        \n",
    "    network = SEQ2POINT().to(set_GPU())\n",
    "\n",
    "#     train_mains,valid_mains,train_appliance,valid_appliance = train_test_split(mains, appliance, test_size=.2, random_state = random_seed)\n",
    "\n",
    "\n",
    "#     train_dataset = TensorDataset(torch.from_numpy(train_mains).float(), torch.from_numpy(train_appliance).float())\n",
    "\n",
    "#     validation_dataset = TensorDataset(torch.from_numpy(valid_mains).float(), torch.from_numpy(valid_appliance).float())\n",
    "\n",
    "    generator = DataGenerator( train_x, train_y, validate_x, validate_y,\n",
    "                              batch_size=1024,\n",
    "                              seq_len=599,\n",
    "                              width=1)\n",
    "\n",
    "#     train_dataloader = torch.utils.data.DataLoader(dataset=generator, \n",
    "#                                   batch_size=20, # how many samples per batch\n",
    "#                                   num_workers=1, # how many subprocesses to use for data loading (higher = more)\n",
    "#                                   shuffle=True) # shuffle the data\n",
    "\n",
    "#     print(train_dataloader)\n",
    "#     for i, s in generator:\n",
    "#         print(i)\n",
    "#         print(s)\n",
    "\n",
    "#     validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "#                                  batch_size=20, \n",
    "#                                  num_workers=1, \n",
    "#                                  shuffle=True) # don't need to shuffle testing data\n",
    "    \n",
    "    train_loss, validation_loss = network.run(generator.generate(), generator.generate())\n",
    "\n",
    "    plot_traces(traces = [train_loss, validation_loss], labels=['training', 'validation'], axis_labels=['Epochs', 'Loss'], title='Training Loss vs Validation Loss per Epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bf361-3227-4f21-9d03-3f6e00770bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followings are the General Settings of your project..\n",
      "{'DATA_PATH': 'data/refit/',\n",
      " 'DESCRIPTION': 'General Settings',\n",
      " 'LOAD_MODEL': '',\n",
      " 'PRE_TRAINED_MODEL_FLAG': False,\n",
      " 'SAVE_PATH': 'models/'}\n",
      "\n",
      "Initializing SEQ2POINT model archiecture\n",
      "\n",
      "Followings are the Model Parameters of your network architecture..\n",
      "{'CONV_KERNEL': [10, 8, 6, 5, 5],\n",
      " 'CONV_LAYERS': 5,\n",
      " 'CONV_PADDING': 0,\n",
      " 'CONV_STRIDE': 1,\n",
      " 'DESCRIPTION': 'Model Parameters',\n",
      " 'INPUT_CHANNELS': [1, 30, 30, 40, 50],\n",
      " 'LEFT_PAD': [4, 3, 2, 2, 2],\n",
      " 'LINEAR_INPUT': [29950, 1024],\n",
      " 'LINEAR_LAYERS': 2,\n",
      " 'LINEAR_OUTPUT': [1024, 1],\n",
      " 'OUTPUT_CHANNELS': [30, 30, 40, 50, 50],\n",
      " 'POOL_KERNEL': [],\n",
      " 'POOL_STRIDE': [],\n",
      " 'RIGHT_PAD': [5, 4, 3, 2, 2],\n",
      " 'SEQUENCE_LENGTH': 599}\n",
      "\n",
      "SEQ2POINT model archiecture has been initialized\n",
      "\n",
      "Followings are the Training Configuration of your experiment..\n",
      "{'DESCRIPTION': 'Training Configuration',\n",
      " 'EARLY_STOPPING_THRESHOLD': 3,\n",
      " 'LEARNING_RATE': 0.001,\n",
      " 'LOSS': 'nn.MSELoss',\n",
      " 'LOSS_REDUCTION': 'mean',\n",
      " 'NUM_EPOCHS': 5,\n",
      " 'OPTIMIZER': 'optim.Adam',\n",
      " 'TRAIN_BATCH_SIZE': 64}\n",
      "\n",
      "Summary of the model architecture\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-1                [-1, 1, 608]              --\n",
      "|    └─Conv1d: 2-2                       [-1, 30, 599]             330\n",
      "|    └─ReLU: 2-3                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-4                [-1, 30, 606]             --\n",
      "|    └─Conv1d: 2-5                       [-1, 30, 599]             7,230\n",
      "|    └─ReLU: 2-6                         [-1, 30, 599]             --\n",
      "|    └─ConstantPad1d: 2-7                [-1, 30, 604]             --\n",
      "|    └─Conv1d: 2-8                       [-1, 40, 599]             7,240\n",
      "|    └─ReLU: 2-9                         [-1, 40, 599]             --\n",
      "|    └─ConstantPad1d: 2-10               [-1, 40, 603]             --\n",
      "|    └─Conv1d: 2-11                      [-1, 50, 599]             10,050\n",
      "|    └─ReLU: 2-12                        [-1, 50, 599]             --\n",
      "|    └─ConstantPad1d: 2-13               [-1, 50, 603]             --\n",
      "|    └─Conv1d: 2-14                      [-1, 50, 599]             12,550\n",
      "|    └─ReLU: 2-15                        [-1, 50, 599]             --\n",
      "├─Sequential: 1-2                        [-1, 1]                   --\n",
      "|    └─Linear: 2-16                      [-1, 1024]                30,669,824\n",
      "|    └─ReLU: 2-17                        [-1, 1024]                --\n",
      "|    └─Linear: 2-18                      [-1, 1]                   1,025\n",
      "==========================================================================================\n",
      "Total params: 30,708,249\n",
      "Trainable params: 30,708,249\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 83.66\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 117.14\n",
      "Estimated Total Size (MB): 118.07\n",
      "==========================================================================================\n",
      "\n",
      "Training the model architecture...\n",
      "Epoch : [1/5] | Step : [100] | Loss : 0.09123952686786652\n",
      "Epoch : [1/5] | Step : [200] | Loss : 0.019048718735575676\n",
      "Epoch : [1/5] | Step : [300] | Loss : 0.0018362286500632763\n",
      "Epoch : [1/5] | Step : [400] | Loss : 0.002770915161818266\n",
      "Epoch : [1/5] | Step : [500] | Loss : 0.00016540670185349882\n",
      "Epoch : [1/5] | Step : [600] | Loss : 0.0022082326468080282\n",
      "Epoch : [1/5] | Step : [700] | Loss : 9.359631076222286e-05\n",
      "Epoch : [1/5] | Step : [800] | Loss : 0.0007664325530640781\n",
      "Epoch : [1/5] | Step : [900] | Loss : 0.0004745084443129599\n",
      "Epoch : [1/5] | Step : [1000] | Loss : 0.001043042168021202\n",
      "Epoch : [1/5] | Step : [1100] | Loss : 0.00036808085860684514\n",
      "Epoch : [1/5] | Step : [1200] | Loss : 0.0003813749644905329\n",
      "Epoch : [1/5] | Step : [1300] | Loss : 0.0006534463027492166\n",
      "Epoch : [1/5] | Step : [1400] | Loss : 0.0001703173911664635\n",
      "Epoch : [1/5] | Step : [1500] | Loss : 0.0035451361909508705\n",
      "Epoch : [1/5] | Step : [1600] | Loss : 0.030299749225378036\n",
      "Epoch : [1/5] | Step : [1700] | Loss : 0.00010291929356753826\n",
      "Epoch : [1/5] | Step : [1800] | Loss : 0.00027640294865705073\n",
      "Epoch : [1/5] | Step : [1900] | Loss : 5.566266736423131e-06\n",
      "Epoch : [1/5] | Step : [2000] | Loss : 0.0001259761629626155\n",
      "Epoch : [1/5] | Step : [2100] | Loss : 3.3396979688404826e-06\n",
      "Epoch : [1/5] | Step : [2200] | Loss : 7.133751932997257e-05\n",
      "Epoch : [1/5] | Step : [2300] | Loss : 1.4784482118557207e-05\n",
      "Epoch : [1/5] | Step : [2400] | Loss : 4.776203786605038e-05\n",
      "Epoch : [1/5] | Step : [2500] | Loss : 0.00015782174887135625\n",
      "Epoch : [1/5] | Step : [2600] | Loss : 3.4134187444578856e-05\n",
      "Epoch : [1/5] | Step : [2700] | Loss : 5.5223308663698845e-06\n",
      "Epoch : [1/5] | Step : [2800] | Loss : 4.952306335326284e-05\n",
      "Epoch : [1/5] | Step : [2900] | Loss : 1.317800888500642e-05\n",
      "Epoch : [1/5] | Step : [3000] | Loss : 3.184835077263415e-05\n",
      "Epoch : [1/5] | Step : [3100] | Loss : 1.856675953604281e-05\n",
      "Epoch : [1/5] | Step : [3200] | Loss : 4.075454853591509e-05\n",
      "Epoch : [1/5] | Step : [3300] | Loss : 7.201258540590061e-06\n",
      "Epoch : [1/5] | Step : [3400] | Loss : 1.7653210306889378e-05\n",
      "Epoch : [1/5] | Step : [3500] | Loss : 0.008785491809248924\n",
      "Epoch : [1/5] | Step : [3600] | Loss : 5.57544881303329e-05\n",
      "Epoch : [1/5] | Step : [3700] | Loss : 1.1143771189381368e-05\n",
      "Epoch : [1/5] | Step : [3800] | Loss : 3.23484382533934e-05\n"
     ]
    }
   ],
   "source": [
    "main(train_x, train_y, validate_x, validate_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea72453-abf4-472a-b8be-59753b7461f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
